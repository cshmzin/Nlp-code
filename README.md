# nlp-code
> **----------------------------------------Nlp codes for study - Bert Model-----------------------------**
![image](https://user-images.githubusercontent.com/38173291/111116489-0da3ce80-85a1-11eb-8a36-c2c639ebe828.png)
> **--------------------------------------------------作者：Ripshun--------------------------------------**

> **---------------------------------------------博客：www.ripshun.com------------------------------------**

> **-------------------------------------------联系方式：cshang1998@gmail.com-----------------------------**



### 本项目记载了通过学习nlp中bert模型相关知识所写的一些程序



### 项目列表：

#### (1) [Bert_test_MASK.ipynb：](https://github.com/cshmzin/nlp-code/blob/main/Bert_test_MASK.ipynb)

> 一个简单的bert测试（测试Mask功能）

> 通过transformers库调用的bert进行测试，测试预训练的功能



#### (2) [Bert_真假新闻分类.ipynb：](https://github.com/cshmzin/nlp-code/blob/main/Bert_真假新闻分类.ipynb])

> 数据来源：kaggle。

> 一个基于bert真假新闻分类（多分类），使用transformers库中bert。


#### (3) [bert命名实体识别.ipynb：](https://github.com/cshmzin/nlp-code/blob/main/bert命名实体识别.ipynb])

> 数据来源：CLUE（细粒度NER任务）

> 一个基于bert的ner任务（10个标签），使用transformers中的bert。

> 测试分数：f1.

#### (4) [Bert-lstm-crf命名实体识别.ipynb：](https://github.com/cshmzin/nlp-code/blob/main/Bert-lstm-crf命名实体识别.ipynb])

> 数据来源：CLUE（细粒度NER任务）

> 一个基于bert的ner任务（4个标签），使用transformers中的bert,并构建模型bert-lstm-crf。。

> 测试分数：f1.


#### (5) [bert+textcnn:文本分类任务:](https://github.com/cshmzin/nlp-code/tree/main/TextClassifier-main])

> 一个基于bert+textcnn的文本分类任务


#### (6) [bert+mrc+crf:命名实体识别:](https://github.com/cshmzin/nlp-code/blob/main/Bert_mrc_crf命名实体识别.ipynb])
> 数据来源：CLUE（细粒度NER任务）

> 一个基于bert的ner任务（4个标签），使用transformers中的bert,并构建模型bert-mrc-crf。。

> 测试分数：f1.

#### (7) [bert:文本相似度:](https://github.com/cshmzin/nlp-code/blob/main/文本相似度.ipynb)
> 数据来源：[讯飞平台](http://challenge.xfyun.cn/topic/info?type=chinese-question-similarity)

> 测试分数：ACC


