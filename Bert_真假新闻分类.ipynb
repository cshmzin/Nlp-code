{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert-真假新闻分类",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMnZgDn9utIfo+VjXnufrue",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3559b4ed80eb42b18232f8d6d8d1ebb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_843a742c2a704c25acb4cdf463099ce3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e1622c66bc50444aa390b84a416874ae",
              "IPY_MODEL_d1a71552876b438e8e716bfd5463e29e"
            ]
          }
        },
        "843a742c2a704c25acb4cdf463099ce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1622c66bc50444aa390b84a416874ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34df0feff5994e49b80e6f99ba2d95cf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109540,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d61173a63b3447a88d5f600045cbf6f"
          }
        },
        "d1a71552876b438e8e716bfd5463e29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a415902690884ead8ee9b2b19fc7c201",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 110k/110k [00:00&lt;00:00, 190kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50226cf2cd4d43eeae6d79e985371f90"
          }
        },
        "34df0feff5994e49b80e6f99ba2d95cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d61173a63b3447a88d5f600045cbf6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a415902690884ead8ee9b2b19fc7c201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50226cf2cd4d43eeae6d79e985371f90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cshmzin/nlp-code/blob/main/Bert_%E7%9C%9F%E5%81%87%E6%96%B0%E9%97%BB%E5%88%86%E7%B1%BB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "CUB_AuvGQU35",
        "outputId": "64ea325f-680a-4ad7-93bf-42c859080dab"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 文件地址：https://www.kaggle.com/c/fake-news-pair-classification-challenge/data\n",
        "# 模型形式：BERT + Linear Classifier\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "#除空\n",
        "empty_title = ((df_train['title2_zh'].isnull()) \\\n",
        "              | (df_train['title1_zh'].isnull()) \\\n",
        "              | (df_train['title2_zh'] == '') \\\n",
        "              | (df_train['title2_zh'] == '0'))\n",
        "df_train = df_train[~empty_title]\n",
        "\n",
        "# 去除过长的样本\n",
        "MAX_LENGTH = 30\n",
        "df_train = df_train[~(df_train.title1_zh.apply(lambda x : len(x)) > MAX_LENGTH)]\n",
        "df_train = df_train[~(df_train.title2_zh.apply(lambda x : len(x)) > MAX_LENGTH)]\n",
        "\n",
        "# 只用 1% 的训练集，看看bert的强大\n",
        "SAMPLE_FRAC = 0.01\n",
        "df_train = df_train.sample(frac=SAMPLE_FRAC, random_state=6666)\n",
        "\n",
        "# 去除没用的列\n",
        "df_train = df_train.reset_index()\n",
        "df_train = df_train.loc[:, ['title1_zh', 'title2_zh', 'label']]\n",
        "df_train.columns = ['text_a', 'text_b', 'label']\n",
        "\n",
        "# 将结果另存成 tsv 供 PyTorch 使用\n",
        "df_train.to_csv(\"train.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"训练样本数量：\", len(df_train))\n",
        "df_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "训练样本数量： 2657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>text_b</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>晚上吃苹果就成毒苹果了吗</td>\n",
              "      <td>早上吃金苹果，晚上吃毒苹果，苹果真不能晚上吃吗？</td>\n",
              "      <td>agreed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>吃酱油会变黑？伤口会留疤？</td>\n",
              "      <td>经常吃酱油会变黑，这件事终于有答案了！</td>\n",
              "      <td>agreed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>加湿器加自来水堪比雾霾</td>\n",
              "      <td>华为金立OPPO：我们手机明年要涨价！网友：有小米就够了</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>有谁希望丧尸病毒爆发，外星人入侵，世界巨</td>\n",
              "      <td>丧尸病毒爆发之后 逃上一个小岛是否是一个最好的方案</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>山药好吃又营养，这么做还能补充维C、降血压</td>\n",
              "      <td>常吃这3种食物，把血液垃圾清理的一干二净，还能降低血压</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  text_a                        text_b      label\n",
              "0           晚上吃苹果就成毒苹果了吗      早上吃金苹果，晚上吃毒苹果，苹果真不能晚上吃吗？     agreed\n",
              "1          吃酱油会变黑？伤口会留疤？           经常吃酱油会变黑，这件事终于有答案了！     agreed\n",
              "2            加湿器加自来水堪比雾霾  华为金立OPPO：我们手机明年要涨价！网友：有小米就够了  unrelated\n",
              "3   有谁希望丧尸病毒爆发，外星人入侵，世界巨     丧尸病毒爆发之后 逃上一个小岛是否是一个最好的方案  unrelated\n",
              "4  山药好吃又营养，这么做还能补充维C、降血压   常吃这3种食物，把血液垃圾清理的一干二净，还能降低血压  unrelated"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkj3XQFpkYyi",
        "outputId": "a71145ed-7957-48b3-9176-85339688ada2"
      },
      "source": [
        "df_train.label.value_counts() / len(df_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "unrelated    0.675574\n",
              "agreed       0.292811\n",
              "disagreed    0.031615\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "6Iu_M-lZlB2v",
        "outputId": "1a9fd098-f057-40a5-aa50-839a2a7c1de4"
      },
      "source": [
        "df_test = pd.read_csv(\"test.csv\")\n",
        "df_test = df_test.loc[:, [\"title1_zh\", \"title2_zh\", \"id\"]]\n",
        "df_test.columns = [\"text_a\", \"text_b\", \"Id\"]\n",
        "df_test.to_csv(\"test.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"预测样本数：\", len(df_test))\n",
        "df_test.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "预测样本数： 80126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>text_b</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大</td>\n",
              "      <td>辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？</td>\n",
              "      <td>321187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
              "      <td>10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国</td>\n",
              "      <td>321190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗</td>\n",
              "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
              "      <td>321189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
              "      <td>被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！</td>\n",
              "      <td>321193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
              "      <td>中国川贝枇杷膏在美国受到热捧？纯属谣言！</td>\n",
              "      <td>321191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            text_a                       text_b      Id\n",
              "0  萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大  辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？  321187\n",
              "1              萨达姆被捕后告诫美国的一句话，发人深思    10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国  321190\n",
              "2    萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗          萨达姆被捕后告诫美国的一句话，发人深思  321189\n",
              "3              萨达姆被捕后告诫美国的一句话，发人深思  被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！  321193\n",
              "4              萨达姆被捕后告诫美国的一句话，发人深思         中国川贝枇杷膏在美国受到热捧？纯属谣言！  321191"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "3559b4ed80eb42b18232f8d6d8d1ebb1",
            "843a742c2a704c25acb4cdf463099ce3",
            "e1622c66bc50444aa390b84a416874ae",
            "d1a71552876b438e8e716bfd5463e29e",
            "34df0feff5994e49b80e6f99ba2d95cf",
            "6d61173a63b3447a88d5f600045cbf6f",
            "a415902690884ead8ee9b2b19fc7c201",
            "50226cf2cd4d43eeae6d79e985371f90"
          ]
        },
        "id": "-P8Qv8GSmlED",
        "outputId": "583c60f7-a7be-45d1-db50-6778f861e418"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "!pip install transformers tqdm boto3 requests regex -q\n",
        "from transformers import BertTokenizer\n",
        "!pip install pysnooper -q\n",
        "import pysnooper\n",
        "\n",
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"  \n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "\n",
        "class FakeNewsDataset(Dataset):\n",
        "    def __init__(self, mode, tokenizer):\n",
        "        assert mode in [\"train\", \"test\"]\n",
        "        self.mode = mode\n",
        "        #iterator=True pd读取大文件方法\n",
        "        self.df = pd.read_csv(mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n",
        "        self.len = len(self.df)\n",
        "        self.label_map = {'agreed': 0, 'disagreed': 1, 'unrelated': 2}\n",
        "        self.tokenizer = tokenizer  #使用 BERT tokenizer\n",
        "\n",
        "    #@pysnooper.snoop()  # 加入以了解所有转换过程\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode == \"test\":\n",
        "            text_a, text_b = self.df.iloc[idx, :2].values\n",
        "            label_tensor = None\n",
        "        else:\n",
        "            text_a, text_b, label = self.df.iloc[idx, :].values\n",
        "            label_id = self.label_map[label]\n",
        "            label_tensor = torch.tensor(label_id)\n",
        "            \n",
        "        word_pieces = [\"[CLS]\"]\n",
        "        tokens_a = self.tokenizer.tokenize(text_a)\n",
        "        word_pieces += tokens_a + [\"[SEP]\"]\n",
        "        len_a = len(word_pieces)\n",
        "        \n",
        "        tokens_b = self.tokenizer.tokenize(text_b)\n",
        "        word_pieces += tokens_b + [\"[SEP]\"]\n",
        "        len_b = len(word_pieces) - len_a\n",
        "        \n",
        "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
        "        tokens_tensor = torch.tensor(ids)\n",
        "        \n",
        "        segments_tensor = torch.tensor([0] * len_a + [1] * len_b,dtype=torch.long)\n",
        "        \n",
        "        return (tokens_tensor, segments_tensor, label_tensor)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "trainset = FakeNewsDataset(\"train\", tokenizer=tokenizer)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3559b4ed80eb42b18232f8d6d8d1ebb1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHn8Yg4xpr2D",
        "outputId": "6167e37e-1176-4868-f2a1-9e633c3cc092"
      },
      "source": [
        "import torch\n",
        "sample_idx = 0\n",
        "text_a, text_b, label = trainset.df.iloc[sample_idx].values\n",
        "\n",
        "tokens_tensor, segments_tensor, label_tensor = trainset[sample_idx]\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
        "combined_text = \"\".join(tokens)\n",
        "print(combined_text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS]晚上吃苹果就成毒苹果了吗[SEP]早上吃金苹果，晚上吃毒苹果，苹果真不能晚上吃吗？[SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZNy9ADZp5Er"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def create_mini_batch(samples):\n",
        "    tokens_tensors = [s[0] for s in samples]\n",
        "    segments_tensors = [s[1] for s in samples]\n",
        "    \n",
        "    if samples[0][2] is not None:\n",
        "        label_ids = torch.stack([s[2] for s in samples])\n",
        "    else:\n",
        "        label_ids = None\n",
        "    \n",
        "    # zero pad 到同一序列长度\n",
        "    tokens_tensors = pad_sequence(tokens_tensors,batch_first=True)\n",
        "    segments_tensors = pad_sequence(segments_tensors,batch_first=True)\n",
        "    \n",
        "    # attention masks，将 tokens_tensors 不为 zero padding 的位置设为1\n",
        "    masks_tensors = torch.zeros(tokens_tensors.shape,dtype=torch.long)\n",
        "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
        "    \n",
        "    return tokens_tensors, segments_tensors, masks_tensors, label_ids\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "trainloader = DataLoader(trainset,batch_size=BATCH_SIZE,collate_fn=create_mini_batch)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad4EtA18_pGG"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "from IPython.display import clear_output\n",
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
        "NUM_LABELS = 3\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
        "\n",
        "clear_output()\n",
        "#model.config"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNgUDLphBcun"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 此内容为代码格式\n",
        "\n",
        "class BertForSequenceClassification(BertPreTrainedModel):\n",
        "    def __init__(self, config, num_labels=2, ...):\n",
        "        super(BertForSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config, ...)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "          ...\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None, ...):\n",
        "        outputs = self.bert(input_ids, token_type_ids, attention_mask, ...)\n",
        "        ...\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            return loss\n",
        "        elif self.output_attentions:\n",
        "            return all_attentions, logits\n",
        "        return logit\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXdwfRscAckW",
        "outputId": "f69eec93-6a28-4d25-a8a2-c28570fb939a"
      },
      "source": [
        "def get_predictions(model, dataloader, compute_acc=False):\n",
        "    predictions = None\n",
        "    correct = 0\n",
        "    total = 0\n",
        "      \n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            if next(model.parameters()).is_cuda:\n",
        "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
        "            \n",
        "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
        "            outputs = model(input_ids=tokens_tensors,token_type_ids=segments_tensors,attention_mask=masks_tensors)\n",
        "            \n",
        "            logits = outputs[0]\n",
        "            _, pred = torch.max(logits.data, 1)\n",
        "            \n",
        "            if compute_acc:\n",
        "                labels = data[3]\n",
        "                total += labels.size(0)\n",
        "                correct += (pred == labels).sum().item()\n",
        "                \n",
        "            if predictions is None:\n",
        "                predictions = pred\n",
        "            else:\n",
        "                predictions = torch.cat((predictions, pred))\n",
        "    \n",
        "    if compute_acc:\n",
        "        acc = correct / total\n",
        "        return predictions, acc\n",
        "    return predictions\n",
        "    \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "model = model.to(device)\n",
        "_, acc = get_predictions(model, trainloader, compute_acc=True)\n",
        "print(\"classification acc:\", acc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda:0\n",
            "classification acc: 0.26270229582235605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1cZmsyoCZtr",
        "outputId": "a2c45fe1-cfae-4396-b627-a80b613479b9"
      },
      "source": [
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "EPOCHS = 6\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    for data in trainloader:\n",
        "        \n",
        "        tokens_tensors, segments_tensors, \\\n",
        "        masks_tensors, labels = [t.to(device) for t in data]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=tokens_tensors, \n",
        "                        token_type_ids=segments_tensors, \n",
        "                        attention_mask=masks_tensors, \n",
        "                        labels=labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    _, acc = get_predictions(model, trainloader, compute_acc=True)\n",
        "\n",
        "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
        "          (epoch + 1, running_loss, acc))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch 1] loss: 28.292, acc: 0.830\n",
            "[epoch 2] loss: 18.815, acc: 0.884\n",
            "[epoch 3] loss: 14.057, acc: 0.925\n",
            "[epoch 4] loss: 9.776, acc: 0.943\n",
            "[epoch 5] loss: 6.425, acc: 0.971\n",
            "[epoch 6] loss: 4.782, acc: 0.973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "hBpBJQ1NKiR2",
        "outputId": "66c1db0e-f86f-4e1c-c9bb-b8ca769bb10b"
      },
      "source": [
        "testset = FakeNewsDataset(\"test\", tokenizer=tokenizer)\n",
        "testloader = DataLoader(testset, batch_size=256, \n",
        "                        collate_fn=create_mini_batch)\n",
        "\n",
        "predictions = get_predictions(model, testloader)\n",
        "index_map = {v: k for k, v in testset.label_map.items()}\n",
        "\n",
        "df = pd.DataFrame({\"Category\": predictions.tolist()})\n",
        "df['Category'] = df.Category.apply(lambda x: index_map[x])\n",
        "df_pred = pd.concat([testset.df.loc[:, [\"Id\"]], df.loc[:, 'Category']], axis=1)\n",
        "df_pred.to_csv('bert_1_prec_training_samples.csv', index=False)\n",
        "df_pred.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>321187</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>321190</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>321189</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>321193</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>321191</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Id   Category\n",
              "0  321187  unrelated\n",
              "1  321190  unrelated\n",
              "2  321189  unrelated\n",
              "3  321193  unrelated\n",
              "4  321191  unrelated"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "4SMmoJg_LFRr",
        "outputId": "48f443e6-1856-4803-e897-ac01bf778c1d"
      },
      "source": [
        "predictions = get_predictions(model, trainloader)\n",
        "df = pd.DataFrame({\"predicted\": predictions.tolist()})\n",
        "df['predicted'] = df.predicted.apply(lambda x: index_map[x])\n",
        "df1 = pd.concat([trainset.df, df.loc[:, 'predicted']], axis=1)\n",
        "disagreed_tp = ((df1.label == 'disagreed') & \\\n",
        "                (df1.label == df1.predicted) & \\\n",
        "                (df1.text_a.apply(lambda x: True if len(x) < 10 else False)))\n",
        "df1[disagreed_tp].head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>text_b</th>\n",
              "      <th>label</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1605</th>\n",
              "      <td>李天一已被安排出国</td>\n",
              "      <td>李天一即将提前出狱？官方辟谣：仍在服刑！</td>\n",
              "      <td>disagreed</td>\n",
              "      <td>disagreed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2571</th>\n",
              "      <td>沈阳两名女子偷孩子</td>\n",
              "      <td>两名女子偷孩子 沈阳网警辟谣：假的！</td>\n",
              "      <td>disagreed</td>\n",
              "      <td>disagreed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         text_a                text_b      label  predicted\n",
              "1605  李天一已被安排出国  李天一即将提前出狱？官方辟谣：仍在服刑！  disagreed  disagreed\n",
              "2571  沈阳两名女子偷孩子    两名女子偷孩子 沈阳网警辟谣：假的！  disagreed  disagreed"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX35QgYML0LT",
        "outputId": "020319c8-abf7-4269-d577-27785ea435cf"
      },
      "source": [
        "text_a = \"李天一已被安排出国\"\n",
        "text_b = \"李天一即将提前出狱？官方：是的！\"\n",
        "word_pieces = [\"[CLS]\"]\n",
        "tokens_a = tokenizer.tokenize(text_a)\n",
        "word_pieces += tokens_a + [\"[SEP]\"]\n",
        "len_a = len(word_pieces)\n",
        "        \n",
        "tokens_b = tokenizer.tokenize(text_b)\n",
        "word_pieces += tokens_b + [\"[SEP]\"]\n",
        "len_b = len(word_pieces) - len_a\n",
        "\n",
        "ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
        "tokens_tensor = torch.tensor(ids).unsqueeze(0)\n",
        "     \n",
        "segments_tensor = torch.tensor([0] * len_a + [1] * len_b,dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "masks_tensors = torch.zeros(tokens_tensor.shape,dtype=torch.long)\n",
        "masks_tensors = masks_tensors.masked_fill(tokens_tensor != 0, 1).unsqueeze(0)\n",
        "\n",
        "outputs = model(input_ids=tokens_tensor.to(device),token_type_ids=segments_tensor.to(device),attention_mask=masks_tensors.to(device))\n",
        "logits = outputs[0]\n",
        "_, pred = torch.max(logits.data, 1)\n",
        "label_map = {0:'agreed', 1: 'disagreed', 2: 'unrelated'}\n",
        "\n",
        "print(outputs)\n",
        "print(label_map[pred.cpu().tolist()[0]])\n",
        "\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[ 1.5578, -0.0229, -0.4285]], device='cuda:0', grad_fn=<AddmmBackward>),)\n",
            "agreed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7nRG4tDMFQR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}